{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03014f95-dcfa-413b-bc5d-78a0cfa294c0",
   "metadata": {},
   "source": [
    "# Week 1 - Nonlinear Stability Defintions\n",
    "\n",
    "Week 1 introduces the fundamental concepts of nonlinear stability in dynamical systems and relates them to classical linear stability definitions. The focus is on understanding how stability is defined in the nonlinear setting and how these definitions extend or differ from the linear case.\n",
    "\n",
    "The module emphasizes the importance of distinguishing between local and global stability, showing how nonlinear systems may behave differently depending on the size of perturbations from equilibrium. These concepts provide the foundation for analyzing spacecraft attitude motion under nonlinear dynamics.\n",
    "\n",
    "**<ins>Learning Objectives</ins>**\n",
    "\n",
    "- Differentiate between key nonlinear stability concepts (Lyapunov, asymptotic, exponential)\n",
    "- Compare nonlinear stability definitions to their linear counterparts\n",
    "- Understand the distinction between local and global stability in nonlinear systems\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6c5875-3fd3-465a-9086-08672f6ef169",
   "metadata": {},
   "source": [
    "# 1.1 - A brief history of controls\n",
    "\n",
    "Before introducing nonlinear stability concepts, it is useful to recall the core building blocks of classical control theory. These tools form the foundation from which modern and nonlinear methods extend.\n",
    "\n",
    "The notes below do not delve very deep into the theory. Classical controls on its own require a special attnetion and a study on it is recommended to get a feel for the presentation here (i might create a seperate study in my 'Studies' folder for Controls)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ffa434-99c7-4da0-bb27-267d90ce2fcb",
   "metadata": {},
   "source": [
    "## 1.1.1 - Classical Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd3a839-c9c0-42d8-abe1-f2f31e055d0c",
   "metadata": {},
   "source": [
    "Early control theory was largely built on **linear system analysis**, where system dynamics could be approximated as linear differential equations and represented using transfer functions in the Laplace domain.\r\n",
    "This viewpoint made complex systems tractable by turning differential equations into algebra, but it relied on strong assumptions about how systems respond to inputs.\r\n",
    "\r\n",
    "**<ins>What makes a system linear?</ins>**\r\n",
    "\r\n",
    "A system is considered **linear** if it satisfies the principle of superposition. Intuitively, this means the system responds *predictably* and *proportionally* to inputs.\r\n",
    "\r\n",
    "1. **Additivity:**\r\n",
    "If an input $u_1(t)$ produces an output $y_1(t)$ and another input $u_2(t)$ produces an output $y_2(t)$, then applying both inputs together results in the sum of the two responses:\r\n",
    "$$\r\n",
    "u(t) = u_1(t) + u_2(t) \\quad \\Rightarrow \\quad y(t) = y_1(t) + y_2(t).\r\n",
    "$$\r\n",
    "\r\n",
    "2. **Homogeneity (Scaling):**\r\n",
    "If an input $u(t)$ produces an output $y(t)$, then scaling the input by a constant simply scales the output by the same amount:\r\n",
    "$$\r\n",
    "u(t) \\to \\alpha u(t) \\quad \\Rightarrow \\quad y(t) \\to \\alpha y(t).\r\n",
    "$$\r\n",
    "\r\n",
    "Together, these properties imply that the system behaves like a *perfect mixer*: inputs can be broken apart, scaled, recombined, and analyzed independently.\r\n",
    "This is what makes linear systems so mathematically convenient.\r\n",
    "\r\n",
    "**<ins>Time invariance</ins>**\r\n",
    "\r\n",
    "A system is **time-invariant** if its behavior does not depend on *when* an input is applied, only on *what* the input looks like.\r\n",
    "\r\n",
    "If input $x(t)$ produces output $y(t)$, then delaying the input by some amount $T$ produces the same delay in the output:\r\n",
    "$$\r\n",
    "x(t - T) \\;\\Rightarrow\\; y(t - T).\r\n",
    "$$\r\n",
    "\r\n",
    "In other words, the system does not \"age\" or change its rules over time. This assumption is critical for treating the system as something fixed and predictable.\r\n",
    "\r\n",
    "**<ins>Impulse response and the move to the frequency domain</ins>**\r\n",
    "\r\n",
    "A key idea in classical control is that an LTI system can be completely characterized by how it reacts to a very short, sharp input - the **impulse**.\r\n",
    "The impulse acts like a probe that reveals the system's inherent dynamics.\r\n",
    "\r\n",
    "- If the impulse response is $h(t)$, then the output due to any general input $x(t)$ is given by the **convolution integral**:\r\n",
    "\r\n",
    "$$\r\n",
    "y(t) = (x * h)(t) = \\int_{-\\infty}^{\\infty} x(\\tau)\\, h(t - \\tau)\\, d\\tau .\r\n",
    "$$\r\n",
    "\r\n",
    "- While this expression is exact, convolution in the time domain is often cumbersome and unintuitive for design and analysis.\r\n",
    "\r\n",
    "To simplify matters, engineers move to the **Laplace transform** (the $s$-domain), where the mathematics becomes much cleaner:\r\n",
    "\r\n",
    "- Convolution in time turns into **simple multiplication** in the $s$-domain:\r\n",
    "\r\n",
    "$$\r\n",
    "Y(s) = H(s)\\, X(s).\r\n",
    "$$\r\n",
    "\r\n",
    "- The system is then represented by its **transfer function** $G(s)$, defined as the ratio of output to input in the Laplace domain:\r\n",
    "\r\n",
    "$$\r\n",
    "G(s) = \\frac{Y(s)}{U(s)} = H(s).\r\n",
    "$$\r\n",
    "\r\n",
    "In practice, the transfer function is written as a ratio of polynomials:\r\n",
    "\r\n",
    "$$\r\n",
    "G(s) = \\frac{b_m s^m + \\dots + b_1 s + b_0}{a_n s^n + \\dots + a_1 s + a_0}.\r\n",
    "$$\r\n",
    "\r\n",
    "- The **poles** (roots of the denominator) indicate how the system naturally evolves and whether it is stable.\r\n",
    "- The **zeros** (roots of the numerator) influence how inputs are shaped as they pass through the system.\r\n",
    "\r\n",
    "This pole-zero picture gives a compact, intuitive way to reason about system behavior without directly solving differential equations.\r\n",
    "\r\n",
    "**<ins>Frequency-domain techniques</ins>**\r\n",
    "\r\n",
    "Building on the transfer function representation, classical control uses several frequency-domain tools:\r\n",
    "\r\n",
    "- **Bode plots** - show how gain and phase vary with frequency\r\n",
    "- **Nyquist criterion** - uses encirclement of the $-1$ point to assess closed-loop stability\r\n",
    "- **Root locus** - visualizes how closed-loop poles move as controller gain changes\r\n",
    "\r\n",
    "These tools are powerful precisely because **linearity allows global conclusions to be drawn from frequency behavior**-an assumptionthat will later become a major limitation when dealing with nonlinear systems.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7cff97-1df6-4256-adf3-157c415cfd50",
   "metadata": {},
   "source": [
    "## 1.1.2 - Feedback Control"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12d42d4-2208-4510-b40e-417f3c1de141",
   "metadata": {},
   "source": [
    "The central concept of control is **feedback**, where the system output is continually compared against a desired reference.\n",
    "By feeding this information back into the system, the controller can automatically correct errors and counteract disturbances, even when the model is imperfect.\n",
    "\n",
    "**Error definition:**\n",
    "\n",
    "$$\n",
    "e(t) = r(t) - y(t)\n",
    "$$\n",
    "\n",
    "where $r(t)$ is the desired reference (command) and $y(t)$ is the actual system output.\n",
    "\n",
    "**Generic feedback law (PID):**\n",
    "\n",
    "The most widely used classical feedback controller is the **Proportional-Integral-Derivative (PID)** law:\n",
    "\n",
    "$$\n",
    "u(t) = K_p e(t) + K_d \\dot{e}(t) + K_i \\int e(t)\\,dt\n",
    "$$\n",
    "\n",
    "Each term plays a distinct role in shaping the closed-loop response:\n",
    "\n",
    "- **P-term (Proportional):** provides an immediate correction proportional to the current error.\n",
    "- **D-term (Derivative):** reacts to how fast the error is changing, adding damping and improving stability.\n",
    "- **I-term (Integral):** accumulates past error over time, helping eliminate steady-state offsets caused by biases or disturbances.\n",
    "\n",
    "From a systems perspective, feedback does more than \"reduce error\" - it actively **reshapes the system's closed-loop dynamics**.\n",
    "By feeding the output back into the input, the controller modifies the effective equations of motion, allowing engineers to influence stability, response speed, and robustness through gain tuning.\n",
    "\n",
    "**Key insights:**\n",
    "\n",
    "- **Open-loop vs closed-loop:**\n",
    "Without feedback (open loop), system behavior is highly sensitive to modeling errors and disturbances.\n",
    "With feedback (closed loop), deviations are continuously measured and corrected.\n",
    "\n",
    "- **Tradeoffs:**\n",
    "    - Large $K_p$ improves responsiveness but can lead to oscillations.\n",
    "    - Large $K_i$ removes steady-state error but increases the risk of instability.\n",
    "    - Large $K_d$ improves damping but tends to amplify measurement noise.\n",
    "\n",
    "- **Robustness:**\n",
    "Feedback provides resilience against uncertainties, modeling inaccuracies, and external disturbances - a critical requirement in aerospace and other safety-critical systems.\n",
    "\n",
    "Feedback control remains the backbone of classical control, and PID controllers are still widely used today due to their simplicity, reliability, and intuitive tuning - even though their effectiveness relies heavily on linear assumptions. As a result, PID control provides limited guarantees for strongly nonlinear systems, where stability and performance cannot be assured outside a local operating region."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bacd2a-6dbc-43f4-9a71-3ae0745bbb04",
   "metadata": {},
   "source": [
    "## 1.1.3 - State-Space Formulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e75db32-27e5-4bef-a9fe-e33be9514b61",
   "metadata": {},
   "source": [
    "With the rise of digital computation, control theory shifted toward the **state-space** framework, which describes system dynamics using vectors and matrices rather than input-output transfer functions.\n",
    "This representation makes internal system behavior explicit and is especially well suited for computer-based control and analysis.\n",
    "\n",
    "A linear time-invariant system is written as:\n",
    "\n",
    "$$\n",
    "\\dot{x}(t) = A x(t) + B u(t)\n",
    "$$\n",
    "$$\n",
    "y(t) = Cx(t) + Du(t)\n",
    "$$\n",
    "\n",
    "- $x(t)$ = state vector, representing the internal variables that fully describe the system (e.g., position, velocity, attitude, angular rate).\n",
    "- $u(t)$ = control input vector.\n",
    "- $y(t)$ = output vector, representing measured or regulated quantities.\n",
    "- $A, B, C, D$ = constant matrices that encode the system dynamics and input-output relationships.\n",
    "\n",
    "By modeling the system in this form, control design focuses directly on how the **state evolves over time**, rather than only on input-output behavior.\n",
    "\n",
    "**Stability condition:**\n",
    "For continuous-time LTI systems, the equilibrium $x = 0$ is stable if all eigenvalues of the system matrix $A$ have negative real parts.\n",
    "This provides a clear, algebraic test for stability without explicitly solving the system equations.\n",
    "\n",
    "**Design approaches:**\n",
    "\n",
    "- **Pole placement:**\n",
    "Uses state feedback to directly assign the closed-loop eigenvalues, shaping transient response and stability characteristics.\n",
    "\n",
    "- **LQR (Linear Quadratic Regulator):**\n",
    "Computes an optimal state-feedback law by minimizing a quadratic cost function that balances state deviation against control effort.\n",
    "\n",
    "These methods are particularly powerful for **MIMO** (multi-input, multi-output) systems, which are common in aerospace applications such as spacecraft attitude control involving multiple actuators and sensors.\n",
    "\n",
    "The state-space framework also serves as a natural stepping stone toward **nonlinear control**, where similar equations describe system dynamics but without the simplifying assumption of linearity.\n",
    "In that setting, stability and performance can no longer be inferred from eigenvalues alone, motivating alternative analysis tools such as Lyapunov methods.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f8fc78-c2ee-402f-afef-82678c7d54a7",
   "metadata": {},
   "source": [
    "## 1.1.4 - Limitations of Classical Control"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2014a5e0-97ba-43fb-9bad-c6e551e73e21",
   "metadata": {},
   "source": [
    "Despite their success, **linear control methods are inherently local in nature**.\n",
    "They work extremely well near an operating point, but their guarantees weaken as the system moves away from that region.\n",
    "\n",
    "- Linearization about an equilibrium provides only **local stability guarantees**, valid in a small neighborhood around the operating point.\n",
    "- Spacecraft attitude dynamics evolve on the **nonlinear manifold $SO(3)$**, where orientations wrap around and cannot be represented globally using linear coordinates.\n",
    "- Large-angle maneuvers, actuator saturation, and strongly coupled rotational dynamics expose regimes where linear tools become unreliable or misleading.\n",
    "\n",
    "In contrast, **nonlinear control** tackles these challenges by working directly with the nonlinear equations of motion, rather than approximating them locally. This enables:\n",
    "\n",
    "- **Global or almost-global stability results**, depending on system topology and constraints.\n",
    "- Controllers that remain valid across large attitude ranges, not just near a single equilibrium.\n",
    "- Energy-based and geometric approaches, such as **Lyapunov methods**, that reason directly about system behavior rather than local linear properties.\n",
    "\n",
    "**Takeaway:**\n",
    "Classical control theory provides essential intuition and powerful mathematical tools. However, spacecraft dynamics demand methods that go beyond local linear analysis, motivating the study of **nonlinear stability and nonlinear feedback control**.\n",
    "\n",
    "**Note:**\n",
    "Nonlinear control does not replace classical methods - it extends them. The same core principles apply, but the analysis and design tools are adapted to handle large motions, nonlinear geometry, and regimes where linear approximations break down. This shift is essential for ensuring stability and performance in realistic spacecraft maneuvers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45db461-dc69-4f28-9cf0-270762fcb50b",
   "metadata": {},
   "source": [
    "# 1.2 - Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5507f232-e2c0-4082-9564-224dc658bed8",
   "metadata": {},
   "source": [
    "## 1.2.1 - Basic Objects that will define Nonlinear Dynamical Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170840fd-4fca-46ca-868d-ef6004adc218",
   "metadata": {},
   "source": [
    "Before defining stability, we need a precise language to describe how dynamical systems evolve in time.\r\n",
    "This section introduces the basic mathematical objects used in nonlinear systems and control.\r\n",
    "\r\n",
    "**State vector**\r\n",
    "\r\n",
    "$$\r\n",
    "x = (x_1, \\dots, x_N)^T\r\n",
    "$$\r\n",
    "\r\n",
    "The state vector $x$ collects all variables required to completely describe the system's condition at a given time $t$.\r\n",
    "Typical state components include positions, velocities, angular rates, or attitude parameters.\r\n",
    "Once the state is known, the future evolution of the system is fully determined by the equations of motion.\r\n",
    "\r\n",
    "**Equations of motion (EOM)**\r\n",
    "\r\n",
    "The system dynamics describe how the state evolves over time.\r\n",
    "\r\n",
    "- **Non-autonomous system (explicit time dependence):**\r\n",
    "$$\r\n",
    "\\dot{x} = f(x,t)\r\n",
    "$$\r\n",
    "\r\n",
    "Here, the dynamics depend explicitly on time, such as through scheduled inputs or time-varying parameters.\r\n",
    "\r\n",
    "- **Autonomous system (time-invariant dynamics):**\r\n",
    "$$\r\n",
    "\\dot{x} = f(x)\r\n",
    "$$\r\n",
    "\r\n",
    "In this case, the system behavior depends only on the current state.\r\n",
    "Autonomous systems are the standard setting for most stability analysis, since equilibrium behavior can be defined independently of time.\r\n",
    "\r\n",
    "**Control vector**\r\n",
    "\r\n",
    "$$\r\n",
    "u = g(x)\r\n",
    "$$\r\n",
    "\r\n",
    "The control input $u$ is typically chosen as a function of the system state (and possibly reference commands).\r\n",
    "Its purpose is to influence the system dynamics in a desired way, such as stabilizing an equilibrium or tracking a reference trajectory.\r\n",
    "\r\n",
    "**Closed-loop system**\r\n",
    "\r\n",
    "When a control law is applied, the system dynamics become:\r\n",
    "\r\n",
    "$$\r\n",
    "\\dot{x} = f(x,u,t)\r\n",
    "$$\r\n",
    "\r\n",
    "Substituting the control law $u = g(x)$ yields a closed-loop system whose behavior is entirely determined by the state evolution.\r\n",
    "\r\n",
    "**Equilibrium state**\r\n",
    "\r\n",
    "A state vector $x_e$ is said to be an **equilibrium state (equilibrium point)** of the system $\\dot{x} = f(x,t)$ if:\r\n",
    "\r\n",
    "$$\r\n",
    "f(x_e, t) = 0 \\quad \\forall \\, t > t_0\r\n",
    "$$\r\n",
    "\r\n",
    "This implies:\r\n",
    "\r\n",
    "$$\r\n",
    "\\dot{x}_e = 0, \\quad x_e = \\text{constant}\r\n",
    "$$\r\n",
    "\r\n",
    "In words, an equilibrium state is a condition in which the system remains indefinitely if initialized there.\r\n",
    "Stability analysis is concerned with what happens when the system is perturbed slightly away from this equilibrium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a2edd2-4892-4bef-979d-d8ebcc49101f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "891cac2e-4ebe-451a-aa54-d18eae8fbdd0",
   "metadata": {},
   "source": [
    "## 1.2.2 - Stability Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a446ebce-b4a9-4183-a03d-97e248444675",
   "metadata": {},
   "source": [
    "**Defintion of Neighborhood**\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"Images/Wk1_Neighborhood.PNG\" alt=\"Alt text\" width=\"500\"/>\n",
    "</div>\n",
    "\n",
    "Before defining stability, we need a precise way to formalize what it means to be \"close\" to a reference state or trajectory.\n",
    "\n",
    "Given a distance $\\delta > 0$, the **neighborhood** $B_\\delta(x_r(t))$ of a reference state $x_r(t)$ is the set of all states $x(t)$ that lie within $\\delta$ of $x_r(t)$:\n",
    "\n",
    "$$\n",
    "\\| x(t) - x_r(t) \\| < \\delta \\quad \\Rightarrow \\quad x(t) \\in B_\\delta(x_r(t)).\n",
    "$$\n",
    "\n",
    "- Intuitively, $B_\\delta(x_r(t))$ is a \"bubble\" of radius $\\delta$ centered at the reference state $x_r(t)$.\n",
    "- The norm $\\|\\cdot\\|$ defines how distance is measured in the state space (typically the Euclidean, or $L_2$, norm).\n",
    "- If the system state remains inside this bubble over time, it is said to stay in the neighborhood of the reference **trajectory** $x_r(t)$.\n",
    "\n",
    "Neighborhoods provide the geometric language needed to describe stability, by making statements like \"starting close\" and \"remaining close\" mathematically precise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8ed1f5-804c-4bc0-bb1d-0c634b80f116",
   "metadata": {},
   "source": [
    "**<ins>Lagrange Stability (Boundedness)</ins>**\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"Images/Wk1_LagrangeStability.PNG\" alt=\"Alt text\" width=\"500\"/>\n",
    "</div>\n",
    "\n",
    "\n",
    "Lagrange stability formalizes the idea that a system's motion remains **bounded** over time.\n",
    "\n",
    "The motion $x(t)$ is said to be **Lagrange stable** relative to a reference trajectory $x_r(t)$ if there exists a distance $\\delta > 0$ such that:\n",
    "\n",
    "$$\n",
    "x(t) \\in B_\\delta(x_r(t)) \\quad \\forall \\quad t > t_0 .\n",
    "$$\n",
    "\n",
    "Here:\n",
    "- $x(t)$ denotes the system state evolving over time,\n",
    "- $x_r(t)$ is the reference state or trajectory of interest,\n",
    "- $B_\\delta(x_r(t))$ is the neighborhood (bubble) of radius $\\delta$ centered at $x_r(t)$,\n",
    "- $\\delta$ defines the size of the region within which the motion is confined,\n",
    "- $t_0$ is the initial time from which the behavior is considered.\n",
    "\n",
    "Intuitively, this means that once the system state starts within (or enters) some bubble around $x_r(t)$, it will **never escape that bubble** as time progresses. \n",
    "Lagrange stability guarantees that the motion remains bounded for all future time, but it does **not** require the state to move closer to the reference or converge to it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f8a685-42a2-4397-a58e-1846a0c44af2",
   "metadata": {},
   "source": [
    "**<ins>Lyapunov Stability</ins>**\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"Images/Wk1_LyapunovStability.PNG\" alt=\"Alt text\" width=\"500\"/>\n",
    "</div>\n",
    "\n",
    "Lyapunov stability formalizes the idea that trajectories which start **sufficiently close** to a reference state or trajectory remain **arbitrarily close** for all future time.\n",
    "\n",
    "The motion $x(t)$ is said to be **Lyapunov stable** (or simply **stable**) relative to a reference trajectory $x_r(t)$ if, for every tolerance $\\epsilon > 0$, there exists a corresponding distance $\\delta(\\epsilon) > 0$ such that:\n",
    "\n",
    "$$\n",
    "x(t_0) \\in B_\\delta(x_r(t_0)) \\;\\;\\Rightarrow\\;\\; x(t) \\in B_\\epsilon(x_r(t)) \\quad \\forall \\quad t > t_0\n",
    "$$\n",
    "\n",
    "Here:\n",
    "- $x(t)$ denotes the system state evolving over time,\n",
    "- $x_r(t)$ is the reference state or trajectory of interest,\n",
    "- $B_\\delta(x_r(t_0))$ is a neighborhood of radius $\\delta$ around the reference at the initial time $t_0$,\n",
    "- $B_\\epsilon(x_r(t))$ is a (possibly smaller) neighborhood of radius $\\epsilon$ around the reference trajectory at time $t$,\n",
    "- $\\epsilon$ specifies how close we want the trajectory to remain,\n",
    "- $\\delta(\\epsilon)$ specifies how close the initial condition must be to guarantee this level of closeness.\n",
    "\n",
    "Intuitively, this means that if the system starts close enough to the reference, it will **remain arbitrarily close** to it for all future time. Lyapunov stability is stronger than Lagrange stability because it guarantees closeness at a prescribed level, not just boundedness, but it still does **not** require convergence to the reference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a9af77-bb14-44b0-aee3-8b2f2b0d4bb8",
   "metadata": {},
   "source": [
    "**<ins>Asymptotic Stability</ins>**\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"Images/Wk1_AsymptoticStability.PNG\" alt=\"Alt text\" width=\"500\"/>\n",
    "</div>\n",
    "\n",
    "Asymptotic stability strengthens Lyapunov stability by additionally requiring **convergence** to the reference state or trajectory over time.\n",
    "\n",
    "The motion $x(t)$ is said to be **asymptotically stable** relative to a reference trajectory $x_r(t)$ if:\n",
    "\n",
    "1. $x(t)$ is **Lyapunov stable**, and\n",
    "2. There exists a distance $\\delta > 0$ such that:\n",
    "\n",
    "$$\n",
    "x(t_0) \\in B_\\delta(x_r(t_0)) \\;\\;\\Rightarrow\\;\\; \\lim_{t \\to \\infty} x(t) = x_r(t).\n",
    "$$\n",
    "\n",
    "Here:\n",
    "- $x(t)$ denotes the system state evolving over time,\n",
    "- $x_r(t)$ is the reference state or trajectory of interest,\n",
    "- $B_\\delta(x_r(t_0))$ defines how close the system must start to the reference at the initial time $t_0$,\n",
    "- $\\delta$ specifies the size of the region of initial conditions from which convergence is guaranteed.\n",
    "\n",
    "Intuitively, this means that if the system starts close enough to the reference, it will not only remain close for all future time, but will also **eventually converge** to the reference as $t \\to \\infty$. Asymptotic stability therefore combines **closeness** (Lyapunov stability) with **long-term convergence**, and is strictly stronger than Lyapunov stability alone."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6023898d-286d-4aa0-afba-f63bc47522f8",
   "metadata": {},
   "source": [
    "**<ins>Global Stability</ins>**\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"Images/Wk1_GlobalStability.PNG\" alt=\"Alt text\" width=\"500\"/>\n",
    "</div>\n",
    "\n",
    "Global stability extends the previous notions of stability by enlarging the set of allowable initial conditions.\n",
    "\n",
    "The motion $x(t)$ is said to be **globally stable** relative to a reference state or trajectory $x_r(t)$ if the corresponding stability property (e.g., Lyapunov or asymptotic stability) holds for **all initial conditions** $x(t_0)$ in the state space, rather than only those within a local neighborhood of the reference.\n",
    "\n",
    "Here:\n",
    "- $x(t)$ denotes the system state evolving over time,\n",
    "- $x_r(t)$ is the reference state or trajectory of interest,\n",
    "- $x(t_0)$ may be any admissible initial state, not restricted to being close to $x_r(t)$.\n",
    "\n",
    "Intuitively, this means that the system's qualitative behavior (staying close or converging) is guaranteed **regardless of where the motion starts** in the state space. When convergence to the reference is also guaranteed for all initial conditions, the system is said to be **globally asymptotically stable**.\n",
    "\n",
    "**Example**: a damped pendulum is *globally asymptotically stable* at the downward equilibrium - from any initial angle and angular velocity, the system eventually settles at the bottom position.\n",
    "\n",
    "The phase portrait shown above illustrates why global stability must be assessed over the entire state space: although trajectories near the equilibrium may appear well behaved, nonlinear effects can dominate far from the origin, leading to qualitatively different behavior and violating global stability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e3938b-05e5-4ec1-b8b9-105b6f7076cb",
   "metadata": {},
   "source": [
    "**<ins>Summary of Stability Concepts</ins>**\n",
    "\n",
    "| **Type** | **Mathematical Condition** | **Intuition** |\n",
    "|-------------------------|---------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------|\n",
    "| **Lagrange Stability** | $x(t) \\in B_\\delta(x_r(t)) \\;\\; \\forall\\, t > t_0$ | Motion stays **bounded** (never escapes some fixed neighborhood). |\n",
    "| **Lyapunov Stability** | $x(t_0) \\in B_\\delta(x_r(t_0)) \\;\\;\\Rightarrow\\;\\; x(t) \\in B_\\epsilon(x_r(t))$ | If you start **close enough**, you stay **arbitrarily close** for all time. |\n",
    "| **Asymptotic Stability**| $x(t_0) \\in B_\\delta(x_r(t_0)) \\;\\;\\Rightarrow\\;\\; \\lim_{t \\to \\infty} x(t) = x_r(t)$ | If you start close, you stay close and **eventually converge** to the ref. |\n",
    "| **Global Stability** | Stability holds for **any** initial condition $x(t_0)$ | The corresponding stability property holds **regardless of where you start**.|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2ddd25-ff6a-4ade-8beb-7aea2a1c4fe3",
   "metadata": {},
   "source": [
    "# 1.3 - Linearization of Nonlinear systems\n",
    "\n",
    "Nonlinear systems are often difficult to analyze directly, especially when seeking analytical insight or stability guarantees.\r\n",
    "A common and powerful approach is to **linearize** the equations of motion about a reference trajectory or equilibrium point.\r\n",
    "\r\n",
    "Linearization replaces the nonlinear dynamics with a **local linear approximation**, valid only in a neighborhood of the reference motion. This allows classical linear tools to be applied for intuition and preliminary analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35934dd3-3e2d-4f4c-aed1-601b2ad22315",
   "metadata": {},
   "source": [
    "## 1.3.1 - Local Linear Approximation about a reference motion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b59122c-b401-4cb9-83d0-7349cb3804f8",
   "metadata": {},
   "source": [
    "Consider a nominal (reference) state and input trajectory $(x_r(t), u_r(t))$ that exactly satisfies the nonlinear equations of motion:\n",
    "\n",
    "$$\n",
    "\\dot{x}_r = f(x_r, u_r)\n",
    "$$\n",
    "\n",
    "This reference motion defines the operating point about which the system behavior is locally approximated.\n",
    "\n",
    "The full nonlinear system dynamics are given by:\n",
    "\n",
    "$$\n",
    "\\dot{x} = f(x, u)\n",
    "$$\n",
    "\n",
    "To analyze how the actual system behaves relative to the reference, define **departure (perturbation) variables** in the state and control input:\n",
    "\n",
    "$$\n",
    "\\delta x = x - x_r,\n",
    "\\qquad\n",
    "\\delta u = u - u_r\n",
    "$$\n",
    "\n",
    "These quantities represent small deviations of the system from the nominal motion.\n",
    "\n",
    "Substituting $x = x_r + \\delta x$ and $u = u_r + \\delta u$ into the nonlinear dynamics gives:\n",
    "\n",
    "$$\n",
    "\\dot{x} = f(x_r + \\delta x,\\; u_r + \\delta u)\n",
    "$$\n",
    "\n",
    "We are interested in the evolution of the deviation from the reference, defined as:\n",
    "\n",
    "$$\n",
    "\\delta \\dot{x} = \\dot{x} - \\dot{x}_r\n",
    "$$\n",
    "\n",
    "Taylor expansion of $f(x,u)$ about the reference point $(x_r, u_r)$ yields:\n",
    "\n",
    "$$\n",
    "\\dot{x} = f(x_r + \\delta x,\\; u_r + \\delta u)\n",
    "\\approx\n",
    "f(x_r, u_r)\n",
    "+\n",
    "\\frac{\\partial f(x_r, u_r)}{\\partial x}\\, \\delta x\n",
    "+\n",
    "\\frac{\\partial f(x_r, u_r)}{\\partial u}\\, \\delta u\n",
    "+\n",
    "\\text{H.O.T.}\n",
    "$$\n",
    "\n",
    "Substituting this approximation into the expression for $\\delta \\dot{x}$ gives:\n",
    "\n",
    "$$\n",
    "\\delta \\dot{x} =\n",
    "\\Big[\n",
    "f(x_r, u_r) \n",
    "+\n",
    "\\frac{\\partial f(x_r, u_r)}{\\partial x}\\, \\delta x \n",
    "+\n",
    "\\frac{\\partial f(x_r, u_r)}{\\partial u}\\, \\delta u \n",
    "+\n",
    "\\text{H.O.T.}\n",
    "\\Big] -\n",
    "f(x_r, u_r)\n",
    "$$\n",
    "\n",
    "The constant terms $f(x_r, u_r)$ cancel, leaving the **departure dynamics**:\n",
    "\n",
    "$$\n",
    "\\delta \\dot{x} =\n",
    "\\frac{\\partial f(x_r, u_r)}{\\partial x}\\, \\delta x\n",
    "+\n",
    "\\frac{\\partial f(x_r, u_r)}{\\partial u}\\, \\delta u\n",
    "+\n",
    "\\text{H.O.T.}\n",
    "$$\n",
    "\n",
    "Neglecting higher-order terms (H.O.T.), which are small when the deviations are small, the dynamics simplify to a linear approximation:\n",
    "\n",
    "$$\n",
    "\\delta \\dot{x} \\simeq\n",
    "\\frac{\\partial f(x_r, u_r)}{\\partial x}\\, \\delta x\n",
    "+\n",
    "\\frac{\\partial f(x_r, u_r)}{\\partial u}\\, \\delta u\n",
    "$$\n",
    "\n",
    "Define the Jacobian matrices evaluated along the reference trajectory:\n",
    "\n",
    "$$\n",
    "[A] = \\frac{\\partial f(x_r, u_r)}{\\partial x},\n",
    "\\qquad\n",
    "[B] = \\frac{\\partial f(x_r, u_r)}{\\partial u}\n",
    "$$\n",
    "\n",
    "The resulting **linearized system**, which governs the evolution of small perturbations about the reference motion, is therefore:\n",
    "\n",
    "$$\n",
    "\\delta \\dot{x} \\simeq [A]\\, \\delta x + [B]\\, \\delta u\n",
    "$$\n",
    "\n",
    "If the reference motion corresponds to an equilibrium point $(x_e, u_e)$ such that $f(x_e, u_e) = 0$, the perturbation variables coincide with the state itself, and the linearized equations reduce to the familiar linear time-invariant form:\n",
    "\n",
    "$$\n",
    "\\dot{x} \\simeq [A]\\, x + [B]\\, u\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18455626-d7d1-4b56-80c1-9f882a242139",
   "metadata": {},
   "source": [
    "## 1.3.2 - Interpretation, Use, and limitations of linearization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3c443a-c022-4bd6-8a7c-40dc31ba542e",
   "metadata": {},
   "source": [
    "The linearized system describes how **small perturbations** about a reference motion evolve over time. Its states represent deviations from the nominal trajectory, not the full nonlinear system state.\n",
    "\n",
    "Because the linearized dynamics are linear, classical analysis tools—such as eigenvalue analysis, transfer functions, and frequency-domain methods—can be applied to assess **local stability and transient behavior** near the reference motion.\n",
    "\n",
    "However, it is critical to emphasize that linearization is a **local approximation**. This limitation arises because higher-order nonlinear terms are neglected in the Taylor expansion. As a result, the conclusions drawn from the linearized model are valid only within a neighborhood of the reference motion.\n",
    "\n",
    "A nonlinear system may therefore appear stable when linearized near an equilibrium, yet exhibit instability or qualitatively different behavior for larger excursions in the state space. This motivates the use of nonlinear stability tools, such as Lyapunov methods, which reason directly about the full nonlinear dynamics rather than local approximations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2a5c1a-1e4a-455a-9515-95d6c1ca6046",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
